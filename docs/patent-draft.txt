Purpose:
It provides a means by which to outsource LLM computation to anyone with appropriate hardware in a secure manner. Additionally, it provides a function economy properly incentivizing compute nodes. My algorithm connects clients needing computation with free compute nodes who can compute LLM's and return responses. The algorithm uses a few formulas to validate the responses and assign reputation to participating compute nodes. A formula is used to compute and distribute funds supplied by the client compensating compute nodes. The algorithm for validating responses allows the client to validate the response without doing the computation itself.

How it's an improvement:
Distributed computing does exist. However, there are either no or no similar means of distributing LLM computation and validating the response. Secondly, no or no similiar system exists in combination with this to provide an economy that compensates compute nodes.

Problems with other products available:
LLM's are currently centralized requiring access to often censored models such as OpenAI's GPT-3/4. You could offload computation to the community in theory, but not current means of verification exists. A client, who you may want to compensate in order to incentivized them to compute your data could return anything. There currently isn't any way to verify LLM output without doing the computation yourself. Any compute node being compensated will inherently be incentivized to just return random tokens. The client can't verify quickly and efficiently.

Why other products don't work well:
Community driven distributed computing either doesn't exist for LLMs, or is not secure, or does not compensate compute nodes in a self regulating economy. It also is often censored and closed-source.

How this invention is an improvement on them:
It provides security for distributed computing in an efficient manner. Computing of LLM's can be offloaded with and answers can be checked by the client allowing for a trustless system. Secondly, while charity distributed systems exist, none provides a self regulating economy compensating compute nodes.

Components:
#1 Client
#2 Distributor
#3 Compute Node
#4 Verification Algorithm
#5 LLM
#6 Cryptocurrency
#7 Compute Job
#8 Compute Job Input
#9 Compute Job Output

Relationship between components:
#1 sends #7 to #2 along with #6 for payment. #2 distributes #7 to multiple #3. #3's return completed #7. #2 uses #4 to verify output of #3. #4 works as follows. If all completed #7 from #3's match then #7 is forwarded to #1 and all #3's split #6 payment from #1 via #2. Otherwise if two #7's match then the matching #7's are forwarded to #1 via #2 and #6 is distributed to the #3's with matching #7's via #2. If all #7's don't match then the following algorithm is used. #7 contains two sub-components #8 and #9 which are comprised of tokenized words. A random token is selected from #9. All tokens before selected word including #8 are inputted into #5. If the token outputted by the #5 matches then the algorithm repeats N times depending on risk assessment of client. Lastly, the second to last token is checked to ensure #3 didn't use truncate exploit. Last token must be <end> as outputted by #5 when given all prior tokens. If any of these tests fail. Then #6 is reserved and given to no #3 and #7 is given to a new set of #3's. Process is repeated until test is passed. However, if one #3 passes the test then it is rewarded #6 and #7 is forwarded to #1.

Contact Info: 
Dylan Dunn
robodylan123@gmail.com
315-529-4032